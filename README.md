<h1 align="center">Must-Read NLP Papers ( -2019)</h1>

This repository contains important NLP papers (most), well-explained materials that everyone working in the field should know about and read.

I also implements several State-of-the-art NLP models. You can find that on my repo.

Check [the repo](https://github.com/pjlintw?tab=repositories)


## Clustering & Word Embeddings

* Peter F Brown, et al.: Class-Based n-gram Models of Natural Language, 1992.

* Tomas Mikolov, et al.: Efficient Estimation of Word Representations in Vector Space, 2013.

* Tomas Mikolov, et al.: Distributed Representations of Words and Phrases and their Compositionality, NIPS 2013.

* Quoc V. Le and Tomas Mikolov: Distributed Representations of Sentences and Documents, 2014.

* Jeffrey Pennington, et al.: GloVe: Global Vectors for Word Representation, 2014.

* Piotr Bojanowski, et al.: Enriching Word Vectors with Subword Information, 2017.

## Event Recognition

* Amosse Edouard: Event Detection and Analysis On Short Text Messages, 2018

* Deepayan Chakrabarti and Kunal Punera: Event Summarization Using Tweets, ICWSM 2011

* Maria Vargas-Vera and David Celjuska: Event Recognition on News Stories and Semi-Automatic Population of an Ontology, Web Intelligence 2004

## Gated Recurrent Unit

* Junyoung Chung, et al.: Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, CoRR 2014.

## Laguage Modeling

* Yoshua Bengio, et al.: A Neural Probabilistic Language Model, J. of Machine Learning Research, 2003.

## Machine Translation

* Dzmitry Bahdanau, et al.: Neural Machine Translation by Jointly Learning to Align and Translate, 2014.

* Yun Chen, et al.: A Teacher-Student Framework for Zero-Resource Neural Machine Translation, ACL, 2017

* Ashish Vaswani, et al.: Attention Is All You Need, 2017.

## Named Entity Recognition

* Guillaume Lample, et al.: Neural Architectures for Named Entity Recognition, ACL 2016

* Xuezhe Ma, Eduard Hovy: End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF, ACL 2016

* Matthew Peters, et al.: Semi-Supervised Sequence Tagging With Bidirectional Language Models, ACL 2017

* Kevin Clark, et al.: Semi-Supervised Sequence Modeling with Cross-View Training, EMNLP 2018

* Matthew Peters, et al.: Deep Contextualized Word Representations, NAACL 2018

* Abbas Ghaddar and Philippe Lannglais: Robust Lexical Features for Improved Neural Network Named-Entity Recognition, COLING 2018

* Alan Akbik, et al: Contextual String Embeddings for Sequence Labeling, ACL 2018

* Alexei Baevski, et al.: Cloze-driven Pretraining of Self-attention Networks, 2019

## Probabilistic Graphical Models

* John Lafferty, Andrew McCallum, Fernando C.N. Pereira: Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data, ICML 2001.

* Undirected Graphical Models

## Reinforcemnet Learning

* Kristopher D. Asis, et al.: Multi_Step Reinforcement Learning_A Unifying Algorithm, AAAI 2018

## Sequence Models

* Ilya Sutskever, et al.: Sequence to Sequence Learning with Neural Networks, 2014